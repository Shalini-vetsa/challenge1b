# ğŸ“„ Adobe India Hackathon 2025 â€“ Challenge 1B
Persona-Based Document Summarizer

This project solves Challenge 1B of the Adobe India Hackathon 2025 by implementing a persona-driven intelligent document summarizer. It processes PDFs, ranks sections relevant to a given persona and job, and generates personalized summaries using NLP models.

## ğŸ” Problem Statement
Given a set of PDF documents, extract and rank content based on how relevant it is to a specified persona and job description, then summarize the top-ranked sections to generate a personalized document summary.

ğŸ§  Key Features
âœ… PDF text extraction via PyMuPDF (fitz)
âœ… Smart chunking and section title identification
âœ… Persona-relevance ranking using TF-IDF
âœ… Natural Language Summarization using DistilBART (from ğŸ¤— Transformers)
âœ… Docker support for portability
âœ… Outputs structured, explainable JSON results

ğŸ“ Folder Structure
project/
â”‚
â”œâ”€â”€ Collection 1/
â”‚   â”œâ”€â”€ pdfs/                         # Input PDFs
â”‚   â”œâ”€â”€ challenge1b_input.json        # Persona & job description input
â”‚   â””â”€â”€ challenge1b_output.json       # Final output JSON summary
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ text_extraction.py           # PDF to text extraction
â”‚   â”œâ”€â”€ persona_ranking.py           # Relevance scoring (TF-IDF)
â”‚   â””â”€â”€ summarizer.py                # Summarizer using DistilBART
â”‚
â”œâ”€â”€ main.py                          # Entry point
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ Dockerfile                       # Docker build instructions
â””â”€â”€ .dockerignore                    # Files to exclude from Docker context
ğŸ› ï¸ Tech Stack
Component	Tool/Library
Language	Python 3.10
NLP Model	ğŸ¤— Transformers (DistilBART: facebook/distilbart-cnn-12-6)
PDF Parsing	PyMuPDF (fitz)
Relevance Scoring	TF-IDF (Scikit-learn, NLTK)
Containerization	Docker

âš™ï¸ Setup & Execution
ğŸ”¨ Step 1: Build Docker Image
Navigate to the root folder where the Dockerfile is present.
docker build -t adobe_challenge1b .

â–¶ï¸ Step 2: Run the Docker Container
Run the summarizer and mount your current folder into Docker:
docker run --rm -v "${PWD}:/app" adobe_challenge1b

ğŸ“ Output will be generated at:
Collection 1/challenge1b_output.json

ğŸ”„ How It Works
Text Extraction
  -- Extracts text from all pages in the PDFs using PyMuPDF.

Section Chunking
  -- Splits text into clean, readable chunks (~300 words) and tries to associate them with nearby titles.

Persona Relevance Ranking
  -- Compares each chunk to the persona and job description using TF-IDF cosine similarity.
  -- Top 5â€“7 relevant chunks are selected for summarization.

Summarization
  -- Uses facebook/distilbart-cnn-12-6 transformer to summarize selected chunks.
  -- Results include the chunk's original location, relevance score, and summary.

Output Format
Outputs a structured JSON including:
  -- Chunk title
  -- Source PDF filename
  -- Page number(s)
  -- Relevance score
  -- Summarized text

ğŸ“¤ Sample Output Format
[
  {
    "source_file": "file01.pdf",
    "page_range": "2-3",
    "section_title": "Deep Learning Applications",
    "relevance_score": 0.89,
    "summary": "This section discusses real-world applications of deep learning, including healthcare, finance, and natural language processing..."
  },
  {
    "source_file": "file01.pdf",
    "page_range": "4",
    "section_title": "Neural Networks",
    "relevance_score": 0.84,
    "summary": "The neural network architecture is explained with emphasis on forward propagation, backpropagation, and activation functions..."
  }
]